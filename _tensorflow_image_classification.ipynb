{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow  Intro",
      "provenance": [],
      "collapsed_sections": [
        "w4q6VT8N5nPm"
      ],
      "toc_visible": true,
      "mount_file_id": "1CG35nXmya5Nxh7W2CVfeJVycB3InMGP7",
      "authorship_tag": "ABX9TyPHgGHWmpSownnpHOu4StmZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafat97/my-tensorflow/blob/image/_tensorflow_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw_ildTyP4aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYXf37OP4iOH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Image Load using keras.preprocessing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnSJKMNp830H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "DATA_PATH = os.getcwd()+'/drive/My Drive/Colab Notebooks/ball-dataset';\n",
        "data_dir = pathlib.Path(DATA_PATH)\n",
        "print(\"dir = \",data_dir)\n",
        "\n",
        "## number of image \n",
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(\"image_count = \",image_count)\n",
        "\n",
        "CLASS_NAMES = np.array(['ball'])\n",
        "print(\"CLASS_NAMES = \",CLASS_NAMES)\n",
        "\n",
        "balls = list(data_dir.glob('ball/*'))\n",
        "print(balls)\n",
        "\n",
        "# for image_path in balls[:]:\n",
        "#     display.display(Image.open(str(image_path)))\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "BATCH_SIZE = 4\n",
        "IMG_HEIGHT = 200\n",
        "IMG_WIDTH = 200\n",
        "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
        "\n",
        "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
        "                                                     batch_size=BATCH_SIZE,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     classes = list(CLASS_NAMES))\n",
        "\n",
        "train_data_gen\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(4):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      # plt.axis('off')\n",
        "\n",
        "image_batch, label_batch = next(train_data_gen)\n",
        "\n",
        "show_batch(image_batch, label_batch)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4q6VT8N5nPm",
        "colab_type": "text"
      },
      "source": [
        "# Image Load using tf.data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T182jx7C5wFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 4\n",
        "IMG_HEIGHT = 200\n",
        "IMG_WIDTH = 200\n",
        "STEPS_PER_EPOCH = 5\n",
        "# np.ceil(image_count/BATCH_SIZE)\n",
        "\n",
        "DATA_PATH = os.getcwd()+'/drive/My Drive/Colab Notebooks/ball-dataset';\n",
        "data_dir = pathlib.Path(DATA_PATH)\n",
        "print(\"dir = \",data_dir)\n",
        "\n",
        "CLASS_NAMES = np.array(['ball'])\n",
        "print(\"CLASS_NAMES = \",CLASS_NAMES)\n",
        "\n",
        "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*.jpg'))\n",
        "for f in list_ds.take(5):\n",
        "  print(f.numpy())\n",
        "\n",
        "def get_label(file_path):\n",
        "  # convert the path to a list of path components\n",
        "  parts = tf.strings.split(file_path, os.path.sep)\n",
        "  # The second to last is the class-directo\n",
        "  return parts[-2] == CLASS_NAMES\n",
        "\n",
        "\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image to the desired size.\n",
        "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
        "\n",
        "\n",
        "def process_path(file_path):\n",
        "  label = get_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(4):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "  # This is a small dataset, only load it once, and keep it in memory.\n",
        "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "  # fit in memory.\n",
        "  if cache:\n",
        "    if isinstance(cache, str):\n",
        "      ds = ds.cache(cache)\n",
        "    else:\n",
        "      ds = ds.cache()\n",
        "\n",
        "  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "  # Repeat forever\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "  # is training.\n",
        "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "  return ds\n",
        "\n",
        "\n",
        "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "# print(labeled_ds)\n",
        "\n",
        "# for image, label in labeled_ds.take(1):\n",
        "#   print(\"Image shape: \", image.numpy().shape)\n",
        "#   print(\"Label: \", label.numpy())\n",
        "\n",
        "train_ds = prepare_for_training(labeled_ds)\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "show_batch(image_batch.numpy(), label_batch.numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OObb9rE51CBq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6ggbNsC2H-I",
        "colab_type": "text"
      },
      "source": [
        "# Image classification\n",
        "\n",
        "cats and dogs image classification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRVc-ZMU2fvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wD8LLXx9W3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data from url and get the stored path\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqMeeC8xBJYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate train dir and validation dir\n",
        "import pprint\n",
        "data_dir = pathlib.Path(PATH)\n",
        "dir_info = list(data_dir.glob('*'))\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "print(\"data_dir = \",data_dir)\n",
        "print(\"dir_info :\")\n",
        "pprint.pprint(dir_info)\n",
        "print(\"train_dir = \",train_dir)\n",
        "print(\"validation_dir = \",validation_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM87gyeVEAE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate cats & dog dir\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  \n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  \n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  \n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  \n",
        "\n",
        "# separate cats & dog dir count\n",
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print(\"train_cats_dir = \",train_cats_dir)\n",
        "print(\"train_dogs_dir = \",train_dogs_dir)\n",
        "print(\"validation_cats_dir = \",validation_cats_dir)\n",
        "print(\"validation_dogs_dir = \",validation_dogs_dir)\n",
        "print(\"num_cats_tr = \",num_cats_tr)\n",
        "print(\"num_dogs_tr = \",num_dogs_tr)\n",
        "print(\"num_cats_val = \",num_cats_val)\n",
        "print(\"num_dogs_val = \",num_dogs_val)\n",
        "print(\"total_train = \",total_train)\n",
        "print(\"total_val = \",total_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjU3dawXFupv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some variable\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNhhodE8McyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator for our training & validation data\n",
        "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fXgSIulMqC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generator for train data gen & validation data gen data\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB03Vj17NpTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize training images\n",
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXMRhnhDN7Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        # ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWqiIdPYO78Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model create Conv2D->MaxPooling2D->Conv2D->MaxPooling2D->Conv2D->MaxPooling2D->Flatten->Dense->Dense\n",
        "model = Sequential([\n",
        "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(32, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhEcWN-vPlfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the mode with summary\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MLZCTzVQDpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train the model\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=total_train // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=total_val // batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnc8VjvQkjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54iAibk3Qytt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize training results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}